Of course — here’s a polished and professional rewrite of your response (from the second screenshot). I’ve kept your key points and intent intact while improving tone, flow, and clarity:


---

Subject: Re: Performance Testing Feedback

Hi Ula,

Thank you for sharing your feedback. I appreciate your observations and would like to clarify a few points regarding our scope of work and responsibilities.

Our team, ITSS Performance Test Team, is responsible specifically for backend performance testing in NavAnomaly, not for the entire performance testing or full coordination across all components. That said, I agree that we can improve several aspects going forward, and I would like to address your comments point by point below.

1. Scope and Ownership
Our team is handling the backend performance test only. Since our resources are shared across multiple development projects, we are not dedicated solely to NavAnomaly. The official request for backend testing was raised on July 14th in JIRA (INPR-572 by Adam Ramainski). We were not assigned ownership of the entire performance testing process but only for the backend part. This is why we rely on knowledgeable stakeholders across the system to collaborate effectively and ensure proper test execution.


2. Documentation
All documentation related to NavAnomaly performance testing is maintained in Confluence: Performance Testing Documentation. As discussed earlier, Leonid will also prepare a summary of his part for the next Friday meeting to make the progress more transparent.


3. Status and Progress Updates
From the start of our engagement, the backend performance tests have been executed as planned and communicated during our status meetings. The latest results will be presented to the Systems team tomorrow and to the Business team on Friday. The UI performance testing, however, is managed separately by testers assigned full-time to NavAnomaly (e.g., Michal Rokoszka’s team).


4. Knowledge and Support
During the preparation phase, we requested additional support to help address certain system-level questions raised by Leonid. Unfortunately, the only available SME, Raghu, was unavailable in July and August due to other project commitments. Once he returned in September, we finalized and executed the tests as planned, with results shared in the meetings you organized.



To summarize, I regret that this situation has caused concern, and I fully agree that better coordination and communication would help moving forward—especially as we prepare to scale our design load testing from 1,000 to 100,000 funds next year. Given the system’s complexity, proper coordination remains essential. However, since our IT Shared Services team supports multiple projects, detailed coordination of all test types—including performance tests—should ideally be managed by full-time project testers assigned specifically to NavAnomaly.

We remain committed to collaborating closely and ensuring smoother alignment in the future.

Kind regards,
Rafal


---

Would you like me to make it slightly firmer (to emphasize boundaries and accountability more strongly), or keep it neutral and diplomatic as above?
